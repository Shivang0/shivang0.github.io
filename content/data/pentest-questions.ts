import type { Difficulty } from './types'

export type QuestionCategory =
  | 'infrastructure'
  | 'model'
  | 'data'
  | 'api'
  | 'deployment'
  | 'governance'
  | 'integration'
  | 'monitoring'
  | 'agent'
  | 'safety'
  | 'compliance'

export type QuestionPhase =
  | 'pre-engagement'
  | 'reconnaissance'
  | 'assessment'
  | 'post-assessment'

export interface ScopingQuestion {
  id: string
  question: string
  category: QuestionCategory
  phase: QuestionPhase
  importance: 'critical' | 'high' | 'medium' | 'low'
  description: string
  followUpQuestions?: string[]
  relevantTests?: string[]
  notes?: string
}

export const questionCategories: { id: QuestionCategory; label: string; description: string }[] = [
  {
    id: 'infrastructure',
    label: 'Infrastructure',
    description: 'Questions about cloud, network, and compute infrastructure'
  },
  {
    id: 'model',
    label: 'Model Architecture',
    description: 'Questions about ML model design, training, and capabilities'
  },
  {
    id: 'data',
    label: 'Data & Privacy',
    description: 'Questions about training data, user data, and privacy concerns'
  },
  {
    id: 'api',
    label: 'API & Interfaces',
    description: 'Questions about API endpoints, authentication, and rate limiting'
  },
  {
    id: 'deployment',
    label: 'Deployment',
    description: 'Questions about model serving, scaling, and production environment'
  },
  {
    id: 'governance',
    label: 'Governance & Compliance',
    description: 'Questions about policies, regulations, and ethical guidelines'
  },
  {
    id: 'integration',
    label: 'Integration',
    description: 'Questions about third-party integrations, plugins, and tools'
  },
  {
    id: 'monitoring',
    label: 'Monitoring & Logging',
    description: 'Questions about observability, alerts, and audit trails'
  },
  {
    id: 'agent',
    label: 'Autonomous Agents',
    description: 'Questions about AI agents, tool use, and autonomous operations'
  },
  {
    id: 'safety',
    label: 'Safety & Alignment',
    description: 'Questions about guardrails, content moderation, and safety controls'
  },
  {
    id: 'compliance',
    label: 'Regulatory Compliance',
    description: 'Questions about EU AI Act, GDPR, and regulatory requirements'
  }
]

export const scopingQuestions: ScopingQuestion[] = [
  // Infrastructure Questions
  {
    id: 'infra-001',
    question: 'What cloud provider(s) host your AI/ML infrastructure?',
    category: 'infrastructure',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Understanding the cloud environment helps determine attack surface and available security controls.',
    followUpQuestions: [
      'Are you using managed ML services (SageMaker, Vertex AI, Azure ML)?',
      'Is the infrastructure multi-cloud or hybrid?',
      'What regions are deployed?'
    ],
    relevantTests: ['Cloud configuration review', 'IAM policy assessment', 'Network segmentation testing']
  },
  {
    id: 'infra-002',
    question: 'What GPU/TPU infrastructure is used for model training and inference?',
    category: 'infrastructure',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Specialized hardware may have unique security considerations and access patterns.',
    followUpQuestions: [
      'Are GPU clusters shared across teams?',
      'How is GPU memory cleared between jobs?',
      'Are there any custom CUDA kernels in use?'
    ],
    relevantTests: ['GPU memory analysis', 'Side-channel attack assessment', 'Resource isolation testing']
  },
  {
    id: 'infra-003',
    question: 'How is network segmentation implemented between ML components?',
    category: 'infrastructure',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Network isolation prevents lateral movement between training, serving, and data systems.',
    followUpQuestions: [
      'Are training environments isolated from production?',
      'What firewall rules exist between ML services?',
      'Is there VPC peering to other systems?'
    ],
    relevantTests: ['Network penetration testing', 'Firewall rule analysis', 'Traffic analysis']
  },
  {
    id: 'infra-004',
    question: 'What container orchestration platform runs your ML workloads?',
    category: 'infrastructure',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Kubernetes, ECS, or other orchestrators have specific security configurations.',
    followUpQuestions: [
      'What version of Kubernetes is running?',
      'Are pod security policies/standards enforced?',
      'How are secrets managed in containers?'
    ],
    relevantTests: ['Container escape testing', 'Kubernetes RBAC review', 'Image vulnerability scanning']
  },
  {
    id: 'infra-005',
    question: 'Where are model artifacts and checkpoints stored?',
    category: 'infrastructure',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Model storage locations need protection against theft and tampering.',
    followUpQuestions: [
      'Is versioning enabled for model storage?',
      'Who has read/write access to model buckets?',
      'Are models encrypted at rest?'
    ],
    relevantTests: ['Storage access control testing', 'Model integrity verification', 'Backup security review']
  },

  // Model Architecture Questions
  {
    id: 'model-001',
    question: 'What type of model architecture are you using (LLM, Vision, Multi-modal)?',
    category: 'model',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Different architectures have unique attack vectors and security considerations.',
    followUpQuestions: [
      'Is this a foundation model or fine-tuned?',
      'What is the model parameter count?',
      'Are multiple models chained together?'
    ],
    relevantTests: ['Architecture-specific attacks', 'Model fingerprinting', 'Capability assessment']
  },
  {
    id: 'model-002',
    question: 'Is the model using retrieval-augmented generation (RAG)?',
    category: 'model',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'RAG systems have additional attack surface through the retrieval component.',
    followUpQuestions: [
      'What vector database is used?',
      'How is the retrieval corpus curated?',
      'Can users influence what gets retrieved?'
    ],
    relevantTests: ['RAG poisoning tests', 'Retrieval manipulation', 'Context injection attacks']
  },
  {
    id: 'model-003',
    question: 'Does the model have access to external tools or function calling?',
    category: 'model',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Tool-using models can be exploited to perform unauthorized actions.',
    followUpQuestions: [
      'What tools/functions are available to the model?',
      'How are tool calls validated and sanitized?',
      'Can the model execute code?'
    ],
    relevantTests: ['Tool abuse testing', 'Function injection', 'Privilege escalation via tools']
  },
  {
    id: 'model-004',
    question: 'What safety/alignment training has the model received?',
    category: 'model',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Understanding alignment helps assess jailbreak resistance.',
    followUpQuestions: [
      'Was RLHF or Constitutional AI used?',
      'What harmful behavior categories are trained against?',
      'When was the last safety fine-tuning?'
    ],
    relevantTests: ['Jailbreak testing', 'Safety bypass attempts', 'Harmful content generation tests']
  },
  {
    id: 'model-005',
    question: 'Are there any system prompts or hidden instructions?',
    category: 'model',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'System prompts often contain sensitive business logic and can be extracted.',
    followUpQuestions: [
      'How long is the system prompt?',
      'Does it contain any credentials or API keys?',
      'Can the system prompt be modified per-user?'
    ],
    relevantTests: ['Prompt extraction attacks', 'System prompt bypass', 'Instruction hierarchy testing']
  },
  {
    id: 'model-006',
    question: 'What context window length does the model support?',
    category: 'model',
    phase: 'pre-engagement',
    importance: 'medium',
    description: 'Long context windows can be exploited for context manipulation attacks.',
    followUpQuestions: [
      'How is context truncation handled?',
      'Is conversation history persisted?',
      'What happens when context limit is exceeded?'
    ],
    relevantTests: ['Context overflow testing', 'Conversation history manipulation', 'Memory exhaustion']
  },

  // Data & Privacy Questions
  {
    id: 'data-001',
    question: 'What types of data were used to train the model?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Training data composition affects extraction risks and bias concerns.',
    followUpQuestions: [
      'Was PII included in training data?',
      'Were there data licensing restrictions?',
      'How was training data filtered for harmful content?'
    ],
    relevantTests: ['Training data extraction', 'Membership inference', 'PII leakage testing']
  },
  {
    id: 'data-002',
    question: 'How is user conversation data handled and retained?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'User data retention policies affect privacy risks and compliance.',
    followUpQuestions: [
      'What is the data retention period?',
      'Is user data used for further training?',
      'Can users request data deletion?'
    ],
    relevantTests: ['Data retention audit', 'Deletion verification', 'Cross-user data leakage']
  },
  {
    id: 'data-003',
    question: 'Is any sensitive enterprise data accessible to the model?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Enterprise integrations can expose confidential business information.',
    followUpQuestions: [
      'What internal systems can the model query?',
      'Is there document access through RAG?',
      'Are there database connections?'
    ],
    relevantTests: ['Data exfiltration testing', 'Unauthorized access attempts', 'Permission boundary testing']
  },
  {
    id: 'data-004',
    question: 'How are embeddings and vector stores protected?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Embeddings can leak information about the original content.',
    followUpQuestions: [
      'Are embeddings encrypted?',
      'Who has access to the vector database?',
      'Can embeddings be inverted to recover text?'
    ],
    relevantTests: ['Embedding inversion attacks', 'Vector database security', 'Access control testing']
  },
  {
    id: 'data-005',
    question: 'Is differential privacy implemented for training or inference?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'medium',
    description: 'Differential privacy provides formal guarantees against data extraction.',
    followUpQuestions: [
      'What epsilon value is used?',
      'Is privacy budget tracked?',
      'Are noisy gradients used during training?'
    ],
    relevantTests: ['Privacy budget analysis', 'Membership inference attacks', 'Reconstruction attack attempts']
  },

  // API & Interface Questions
  {
    id: 'api-001',
    question: 'How is API authentication implemented?',
    category: 'api',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Authentication mechanisms protect against unauthorized access.',
    followUpQuestions: [
      'Are API keys or OAuth tokens used?',
      'How are credentials rotated?',
      'Is MFA required for API access?'
    ],
    relevantTests: ['Authentication bypass testing', 'Token security analysis', 'Credential stuffing attempts']
  },
  {
    id: 'api-002',
    question: 'What rate limiting is in place for API endpoints?',
    category: 'api',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Rate limiting prevents abuse and denial of service.',
    followUpQuestions: [
      'What are the rate limit thresholds?',
      'Is rate limiting per-user or per-IP?',
      'How is rate limit bypass detected?'
    ],
    relevantTests: ['Rate limit testing', 'DoS assessment', 'Rate limit bypass attempts']
  },
  {
    id: 'api-003',
    question: 'Is there input validation and sanitization on prompts?',
    category: 'api',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Input validation prevents injection attacks and malicious payloads.',
    followUpQuestions: [
      'What characters/patterns are blocked?',
      'Is there a maximum input length?',
      'Are file uploads allowed?'
    ],
    relevantTests: ['Injection testing', 'Input fuzzing', 'Malicious payload testing']
  },
  {
    id: 'api-004',
    question: 'How are API responses filtered for sensitive content?',
    category: 'api',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Output filtering prevents leakage of harmful or sensitive information.',
    followUpQuestions: [
      'Is there PII detection on outputs?',
      'Are harmful content filters applied?',
      'Can filters be bypassed with encoding?'
    ],
    relevantTests: ['Output filter bypass', 'PII leakage testing', 'Harmful content extraction']
  },
  {
    id: 'api-005',
    question: 'Are there separate endpoints for different user tiers or capabilities?',
    category: 'api',
    phase: 'pre-engagement',
    importance: 'medium',
    description: 'Tiered access should be properly enforced at the API level.',
    followUpQuestions: [
      'What capabilities differ between tiers?',
      'How is tier enforcement implemented?',
      'Can tier restrictions be bypassed?'
    ],
    relevantTests: ['Authorization testing', 'Privilege escalation', 'Tier boundary testing']
  },
  {
    id: 'api-006',
    question: 'Is the API exposed directly to the internet or behind a gateway?',
    category: 'api',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'API gateways provide additional security controls and monitoring.',
    followUpQuestions: [
      'What WAF rules are in place?',
      'Is there bot detection?',
      'Are requests logged and monitored?'
    ],
    relevantTests: ['WAF bypass testing', 'Direct API access attempts', 'Bot detection evasion']
  },

  // Deployment Questions
  {
    id: 'deploy-001',
    question: 'What is the model serving infrastructure (TensorRT, vLLM, TGI)?',
    category: 'deployment',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Serving frameworks have different security characteristics and vulnerabilities.',
    followUpQuestions: [
      'What version of the serving framework?',
      'Are there known CVEs for this version?',
      'Is the serving layer hardened?'
    ],
    relevantTests: ['Framework vulnerability assessment', 'Configuration review', 'Exploit testing']
  },
  {
    id: 'deploy-002',
    question: 'How are model updates deployed to production?',
    category: 'deployment',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Model deployment pipelines can be compromised to inject malicious models.',
    followUpQuestions: [
      'Is there CI/CD for model deployment?',
      'Are models signed and verified?',
      'Who can approve production deployments?'
    ],
    relevantTests: ['Pipeline security review', 'Model tampering tests', 'Deployment access control']
  },
  {
    id: 'deploy-003',
    question: 'Is there a staging or canary deployment environment?',
    category: 'deployment',
    phase: 'pre-engagement',
    importance: 'medium',
    description: 'Non-production environments may have weaker security controls.',
    followUpQuestions: [
      'Is staging data production-like?',
      'Are staging credentials different from production?',
      'Can staging access production resources?'
    ],
    relevantTests: ['Environment isolation testing', 'Credential reuse checks', 'Lateral movement attempts']
  },
  {
    id: 'deploy-004',
    question: 'How is model versioning and rollback handled?',
    category: 'deployment',
    phase: 'pre-engagement',
    importance: 'medium',
    description: 'Rollback capabilities are important for incident response.',
    followUpQuestions: [
      'How quickly can you rollback?',
      'Are previous model versions retained?',
      'Is there version-specific logging?'
    ],
    relevantTests: ['Rollback procedure review', 'Version integrity verification', 'Access control on versions']
  },
  {
    id: 'deploy-005',
    question: 'Are there multiple model replicas for high availability?',
    category: 'deployment',
    phase: 'pre-engagement',
    importance: 'medium',
    description: 'Replica configuration affects consistency and attack surface.',
    followUpQuestions: [
      'How many replicas run concurrently?',
      'Is there geographic distribution?',
      'How is load balancing implemented?'
    ],
    relevantTests: ['Consistency testing', 'Failover security', 'Load balancer bypass']
  },

  // Governance & Compliance Questions
  {
    id: 'gov-001',
    question: 'What regulatory requirements apply (GDPR, HIPAA, SOC2)?',
    category: 'governance',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Compliance requirements define mandatory security controls.',
    followUpQuestions: [
      'Are there specific AI regulations to comply with (EU AI Act)?',
      'What certifications are held or required?',
      'Are there industry-specific requirements?'
    ],
    relevantTests: ['Compliance gap analysis', 'Control effectiveness testing', 'Documentation review']
  },
  {
    id: 'gov-002',
    question: 'Is there an AI ethics review process?',
    category: 'governance',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Ethics reviews help identify potential misuse scenarios.',
    followUpQuestions: [
      'Who conducts ethics reviews?',
      'What criteria are evaluated?',
      'Are there documented use case restrictions?'
    ],
    relevantTests: ['Policy review', 'Restricted use case testing', 'Misuse scenario assessment']
  },
  {
    id: 'gov-003',
    question: 'How are model decisions explained and documented?',
    category: 'governance',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Explainability requirements affect logging and audit capabilities.',
    followUpQuestions: [
      'Is there a model card or documentation?',
      'Are individual predictions logged?',
      'Can users request explanations?'
    ],
    relevantTests: ['Explanation manipulation', 'Documentation accuracy', 'Audit trail completeness']
  },
  {
    id: 'gov-004',
    question: 'What is the incident response plan for AI-specific issues?',
    category: 'governance',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'AI incidents require specialized response procedures.',
    followUpQuestions: [
      'Who is on the AI incident response team?',
      'What constitutes an AI security incident?',
      'How quickly can the model be taken offline?'
    ],
    relevantTests: ['Response time assessment', 'Communication channel testing', 'Escalation procedure review']
  },
  {
    id: 'gov-005',
    question: 'Are there acceptable use policies for the AI system?',
    category: 'governance',
    phase: 'pre-engagement',
    importance: 'medium',
    description: 'AUPs define boundaries that should be technically enforced.',
    followUpQuestions: [
      'What uses are prohibited?',
      'How are violations detected?',
      'What are the consequences of violations?'
    ],
    relevantTests: ['Policy enforcement testing', 'Prohibited use attempts', 'Detection capability assessment']
  },

  // Integration Questions
  {
    id: 'int-001',
    question: 'What third-party APIs does the model interact with?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'External integrations expand the attack surface significantly.',
    followUpQuestions: [
      'How are API credentials stored?',
      'What data is sent to third parties?',
      'Are there fallback mechanisms if APIs fail?'
    ],
    relevantTests: ['Integration security review', 'Credential exposure testing', 'SSRF via integrations']
  },
  {
    id: 'int-002',
    question: 'Are there plugins or extensions that can be added?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Plugin systems can introduce untrusted code execution.',
    followUpQuestions: [
      'How are plugins vetted and approved?',
      'What permissions do plugins have?',
      'Can users install custom plugins?'
    ],
    relevantTests: ['Plugin security review', 'Malicious plugin testing', 'Permission boundary testing']
  },
  {
    id: 'int-003',
    question: 'Is the model integrated with internal enterprise systems?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Enterprise integrations can provide access to sensitive internal resources.',
    followUpQuestions: [
      'What systems can the model access (email, docs, databases)?',
      'Are there service accounts used for integrations?',
      'Is there row-level security on data access?'
    ],
    relevantTests: ['Unauthorized access testing', 'Service account abuse', 'Data exfiltration attempts']
  },
  {
    id: 'int-004',
    question: 'How do webhooks and callbacks work?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Webhooks can be exploited for SSRF and data exfiltration.',
    followUpQuestions: [
      'Are webhook destinations validated?',
      'What data is included in webhooks?',
      'Are webhooks authenticated?'
    ],
    relevantTests: ['SSRF testing', 'Webhook manipulation', 'Exfiltration via callbacks']
  },
  {
    id: 'int-005',
    question: 'Are there browser or mobile integrations?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Client-side integrations have additional security considerations.',
    followUpQuestions: [
      'Is there a browser extension?',
      'What permissions do client integrations require?',
      'Is client-side prompt caching used?'
    ],
    relevantTests: ['Client-side security review', 'Permission abuse testing', 'Local data exposure']
  },

  // Monitoring Questions
  {
    id: 'mon-001',
    question: 'What logging is in place for model inputs and outputs?',
    category: 'monitoring',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Comprehensive logging is essential for security monitoring and forensics.',
    followUpQuestions: [
      'Are full prompts and responses logged?',
      'How long are logs retained?',
      'Is PII redacted from logs?'
    ],
    relevantTests: ['Log completeness assessment', 'Log tampering attempts', 'Sensitive data in logs']
  },
  {
    id: 'mon-002',
    question: 'Are there anomaly detection systems for unusual usage patterns?',
    category: 'monitoring',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Anomaly detection helps identify attacks and misuse in progress.',
    followUpQuestions: [
      'What patterns trigger alerts?',
      'How quickly are anomalies investigated?',
      'Is there ML-based detection?'
    ],
    relevantTests: ['Detection evasion testing', 'Alert threshold testing', 'False positive analysis']
  },
  {
    id: 'mon-003',
    question: 'How are prompt injection attempts detected and logged?',
    category: 'monitoring',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Injection detection is critical for protecting LLM applications.',
    followUpQuestions: [
      'What injection patterns are detected?',
      'Is there real-time blocking or just logging?',
      'How often are detection rules updated?'
    ],
    relevantTests: ['Detection bypass testing', 'New injection technique testing', 'Rule coverage assessment']
  },
  {
    id: 'mon-004',
    question: 'Is there monitoring for model performance degradation or drift?',
    category: 'monitoring',
    phase: 'pre-engagement',
    importance: 'medium',
    description: 'Performance drift may indicate attacks or data poisoning.',
    followUpQuestions: [
      'What metrics are tracked?',
      'Are there automated alerts for drift?',
      'How is baseline performance established?'
    ],
    relevantTests: ['Drift simulation', 'Metric manipulation', 'Alert threshold testing']
  },
  {
    id: 'mon-005',
    question: 'How are security events correlated across the ML stack?',
    category: 'monitoring',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Correlation helps identify sophisticated multi-stage attacks.',
    followUpQuestions: [
      'Is there a SIEM integration?',
      'Are model events correlated with infrastructure events?',
      'What is the mean time to detect (MTTD)?'
    ],
    relevantTests: ['Multi-stage attack simulation', 'Alert correlation testing', 'Detection gap analysis']
  },

  // Assessment Phase Questions
  {
    id: 'assess-001',
    question: 'What is the testing window and approved hours?',
    category: 'governance',
    phase: 'assessment',
    importance: 'critical',
    description: 'Testing windows ensure minimal disruption and proper coordination.',
    followUpQuestions: [
      'Are there blackout periods?',
      'What timezone for testing hours?',
      'Who should be notified during testing?'
    ],
    relevantTests: ['All testing activities'],
    notes: 'Critical for rules of engagement'
  },
  {
    id: 'assess-002',
    question: 'What accounts and access levels will be provided for testing?',
    category: 'api',
    phase: 'assessment',
    importance: 'critical',
    description: 'Test accounts should mirror realistic user access.',
    followUpQuestions: [
      'Are there multiple tier test accounts?',
      'Is there an admin test account?',
      'Are test accounts monitored separately?'
    ],
    relevantTests: ['All authentication and authorization tests']
  },
  {
    id: 'assess-003',
    question: 'Is there a dedicated test environment or will testing be on production?',
    category: 'deployment',
    phase: 'assessment',
    importance: 'critical',
    description: 'Test environment isolation prevents production impact.',
    followUpQuestions: [
      'Is test data production-like?',
      'Are there shared resources with production?',
      'Can test actions affect real users?'
    ],
    relevantTests: ['All destructive or high-impact tests']
  },
  {
    id: 'assess-004',
    question: 'What is the emergency contact procedure if issues are discovered?',
    category: 'governance',
    phase: 'assessment',
    importance: 'critical',
    description: 'Clear escalation paths enable rapid response to critical findings.',
    followUpQuestions: [
      'Who are the primary and secondary contacts?',
      'What communication channels are preferred?',
      'What constitutes an emergency finding?'
    ],
    relevantTests: ['Critical vulnerability discovery scenarios']
  },

  // Post-Assessment Questions
  {
    id: 'post-001',
    question: 'What is the preferred format and detail level for the report?',
    category: 'governance',
    phase: 'post-assessment',
    importance: 'high',
    description: 'Report format should meet stakeholder needs.',
    followUpQuestions: [
      'Is there a required report template?',
      'Should findings include proof-of-concept code?',
      'Who will receive the report?'
    ],
    relevantTests: ['N/A - Reporting requirement']
  },
  {
    id: 'post-002',
    question: 'What is the process for validating remediation of findings?',
    category: 'governance',
    phase: 'post-assessment',
    importance: 'high',
    description: 'Remediation verification ensures issues are properly fixed.',
    followUpQuestions: [
      'Is retesting included in scope?',
      'How will remediation timeline be tracked?',
      'Who approves closure of findings?'
    ],
    relevantTests: ['Remediation validation testing']
  },
  {
    id: 'post-003',
    question: 'Are there data handling requirements for assessment artifacts?',
    category: 'data',
    phase: 'post-assessment',
    importance: 'high',
    description: 'Test data and artifacts may contain sensitive information.',
    followUpQuestions: [
      'Should test data be destroyed after assessment?',
      'Are there retention requirements for evidence?',
      'How should sensitive findings be transmitted?'
    ],
    relevantTests: ['N/A - Data handling requirement']
  },

  // Autonomous Agent Questions
  {
    id: 'agent-001',
    question: 'What agent framework is being used (LangChain, AutoGPT, CrewAI, custom)?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Different agent frameworks have different security characteristics and known vulnerabilities.',
    followUpQuestions: [
      'What version of the framework?',
      'Are there any custom modifications?',
      'Have known CVEs been addressed?'
    ],
    relevantTests: ['Framework vulnerability assessment', 'Configuration review', 'Known exploit testing']
  },
  {
    id: 'agent-002',
    question: 'How is agent memory implemented (short-term, long-term, episodic)?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Agent memory systems can be poisoned or manipulated to influence future behavior.',
    followUpQuestions: [
      'Where is memory stored?',
      'How long is memory retained?',
      'Can memory be modified by users?'
    ],
    relevantTests: ['Memory poisoning attacks', 'Persistence testing', 'Memory isolation testing']
  },
  {
    id: 'agent-003',
    question: 'What tools and functions can the agent access?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Tool access determines the potential impact of agent compromise.',
    followUpQuestions: [
      'Can the agent execute code?',
      'Does the agent have file system access?',
      'Can the agent make network requests?'
    ],
    relevantTests: ['Tool abuse testing', 'Unauthorized action attempts', 'Capability escalation']
  },
  {
    id: 'agent-004',
    question: 'How is memory poisoning prevented?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Memory poisoning allows attackers to persistently influence agent behavior.',
    followUpQuestions: [
      'Is memory content validated?',
      'Are there integrity checks on stored memories?',
      'Can external content enter memory?'
    ],
    relevantTests: ['Memory injection attacks', 'Persistence bypass', 'Memory integrity testing']
  },
  {
    id: 'agent-005',
    question: 'What prevents goal modification attacks?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Goal hijacking redirects agents from intended objectives to attacker goals.',
    followUpQuestions: [
      'Are goals hardcoded or dynamic?',
      'Can user input influence goals?',
      'How are goal priorities enforced?'
    ],
    relevantTests: ['Goal hijacking attempts', 'Priority manipulation', 'Objective injection']
  },
  {
    id: 'agent-006',
    question: 'Are there human-in-the-loop checkpoints for sensitive operations?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Human approval gates prevent autonomous escalation of harmful actions.',
    followUpQuestions: [
      'What operations require human approval?',
      'Can approval requirements be bypassed?',
      'What is the timeout for approvals?'
    ],
    relevantTests: ['Approval bypass testing', 'Timeout exploitation', 'Checkpoint circumvention']
  },
  {
    id: 'agent-007',
    question: 'What emergency stop mechanisms exist?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Kill switches are essential for stopping runaway agent behavior.',
    followUpQuestions: [
      'How quickly can agents be stopped?',
      'Who has authority to trigger emergency stop?',
      'Are there automated stop conditions?'
    ],
    relevantTests: ['Emergency stop effectiveness', 'Kill switch bypass', 'Automated stop trigger testing']
  },
  {
    id: 'agent-008',
    question: 'How is agent-to-agent communication secured?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Multi-agent systems can have communication channels exploited.',
    followUpQuestions: [
      'Can agents communicate with each other?',
      'Is inter-agent communication authenticated?',
      'Can external parties inject messages?'
    ],
    relevantTests: ['Message injection', 'Agent impersonation', 'Communication channel security']
  },
  {
    id: 'agent-009',
    question: 'Are there replay attack protections for agent actions?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Replay attacks can cause agents to repeat sensitive operations.',
    followUpQuestions: [
      'Are action requests timestamped?',
      'Is there nonce/idempotency protection?',
      'How are duplicate actions detected?'
    ],
    relevantTests: ['Replay attack testing', 'Duplicate action exploitation', 'Timestamp manipulation']
  },
  {
    id: 'agent-010',
    question: 'How is agent sandboxing implemented?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Sandbox escapes allow agents to access unauthorized resources.',
    followUpQuestions: [
      'What containerization is used?',
      'Are there filesystem restrictions?',
      'What network access is allowed?'
    ],
    relevantTests: ['Sandbox escape testing', 'Container breakout', 'Network isolation testing']
  },

  // Safety & Alignment Questions
  {
    id: 'safety-001',
    question: 'What input guardrails are implemented?',
    category: 'safety',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Input guardrails are the first line of defense against harmful prompts.',
    followUpQuestions: [
      'Is there prompt classification?',
      'Are known jailbreak patterns detected?',
      'What categories are blocked?'
    ],
    relevantTests: ['Guardrail bypass testing', 'Input filter evasion', 'Pattern detection assessment']
  },
  {
    id: 'safety-002',
    question: 'How are jailbreak attempts detected?',
    category: 'safety',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Jailbreak detection identifies attempts to bypass safety training.',
    followUpQuestions: [
      'What detection methods are used?',
      'Is there ML-based detection?',
      'How often are detectors updated?'
    ],
    relevantTests: ['Known jailbreak testing', 'Novel jailbreak attempts', 'Detection evasion']
  },
  {
    id: 'safety-003',
    question: 'What topic restrictions are enforced?',
    category: 'safety',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Topic restrictions limit what the model will discuss.',
    followUpQuestions: [
      'Is there a list of prohibited topics?',
      'How are edge cases handled?',
      'Can restrictions be modified per-user?'
    ],
    relevantTests: ['Topic restriction bypass', 'Boundary testing', 'Edge case exploitation']
  },
  {
    id: 'safety-004',
    question: 'Has guardrail bypass testing been conducted?',
    category: 'safety',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Understanding previous testing helps identify coverage gaps.',
    followUpQuestions: [
      'When was the last red team assessment?',
      'What bypass methods were tested?',
      'Were issues remediated?'
    ],
    relevantTests: ['Known bypass retesting', 'New technique testing', 'Remediation validation']
  },
  {
    id: 'safety-005',
    question: 'What output content moderation is applied?',
    category: 'safety',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Output moderation prevents harmful content generation.',
    followUpQuestions: [
      'Is there real-time filtering?',
      'What categories are flagged?',
      'Can moderation be bypassed with encoding?'
    ],
    relevantTests: ['Output filter bypass', 'Encoding attacks', 'Category coverage testing']
  },
  {
    id: 'safety-006',
    question: 'Is toxicity detection implemented?',
    category: 'safety',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Toxicity detection prevents harmful, abusive, or offensive outputs.',
    followUpQuestions: [
      'What toxicity classifier is used?',
      'What is the detection threshold?',
      'How are false positives handled?'
    ],
    relevantTests: ['Toxicity detection evasion', 'Threshold manipulation', 'False positive analysis']
  },
  {
    id: 'safety-007',
    question: 'How is PII detection implemented in outputs?',
    category: 'safety',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'PII detection prevents leakage of personal information.',
    followUpQuestions: [
      'What PII types are detected?',
      'Is there entity recognition?',
      'How is detected PII handled?'
    ],
    relevantTests: ['PII leakage testing', 'Entity extraction bypass', 'Detection coverage assessment']
  },
  {
    id: 'safety-008',
    question: 'Is bias testing conducted on model outputs?',
    category: 'safety',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Bias testing identifies discriminatory or unfair outputs.',
    followUpQuestions: [
      'What bias categories are tested?',
      'How frequently is testing done?',
      'Are there automated bias checks?'
    ],
    relevantTests: ['Bias elicitation testing', 'Fairness assessment', 'Demographic parity analysis']
  },

  // Regulatory Compliance Questions
  {
    id: 'comp-001',
    question: 'What is the EU AI Act risk category for this system?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'EU AI Act risk categorization determines compliance requirements.',
    followUpQuestions: [
      'Has formal risk assessment been conducted?',
      'Are there high-risk use cases?',
      'What is the primary deployment region?'
    ],
    relevantTests: ['Risk categorization validation', 'Control gap analysis', 'Documentation review']
  },
  {
    id: 'comp-002',
    question: 'What conformity assessment requirements apply?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'High-risk AI systems require conformity assessments under EU AI Act.',
    followUpQuestions: [
      'Is third-party assessment required?',
      'What technical documentation exists?',
      'Are there notified body requirements?'
    ],
    relevantTests: ['Documentation completeness', 'Technical requirement validation', 'Process review']
  },
  {
    id: 'comp-003',
    question: 'What transparency obligations must be met?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'AI systems have disclosure requirements about their nature and capabilities.',
    followUpQuestions: [
      'Is AI nature disclosed to users?',
      'Are limitations documented?',
      'Is there a model card or fact sheet?'
    ],
    relevantTests: ['Disclosure compliance', 'Documentation accuracy', 'User notification testing']
  },
  {
    id: 'comp-004',
    question: 'How does GDPR apply to this AI system?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'GDPR has specific requirements for AI processing of personal data.',
    followUpQuestions: [
      'Is personal data used in training?',
      'Are there automated decisions affecting individuals?',
      'Is right to explanation required?'
    ],
    relevantTests: ['Data processing review', 'Rights implementation testing', 'Consent verification']
  },
  {
    id: 'comp-005',
    question: 'Are there HIPAA or healthcare AI requirements?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Healthcare AI has strict requirements under HIPAA and FDA guidance.',
    followUpQuestions: [
      'Does the system process PHI?',
      'Is there a BAA requirement?',
      'Does FDA medical device regulation apply?'
    ],
    relevantTests: ['PHI handling review', 'BAA compliance verification', 'FDA requirement assessment']
  },
  {
    id: 'comp-006',
    question: 'What financial regulations apply (SOX, GLBA, PCI-DSS)?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Financial AI systems have extensive regulatory requirements.',
    followUpQuestions: [
      'Is financial data processed?',
      'Are there model risk management requirements?',
      'Is there SR 11-7 applicability?'
    ],
    relevantTests: ['Financial data handling', 'Model governance review', 'Regulatory control testing']
  },
  {
    id: 'comp-007',
    question: 'Is NIST AI RMF being followed?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'NIST AI Risk Management Framework provides structured approach to AI governance.',
    followUpQuestions: [
      'Which AI RMF functions are implemented?',
      'Is there formal risk assessment documentation?',
      'How is risk measured and tracked?'
    ],
    relevantTests: ['Framework implementation review', 'Risk documentation audit', 'Control effectiveness testing']
  },
  {
    id: 'comp-008',
    question: 'What is the ISO 42001 certification status?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'ISO 42001 is the international standard for AI management systems.',
    followUpQuestions: [
      'Is certification in progress or achieved?',
      'What AIMS controls are implemented?',
      'Are there third-party audits?'
    ],
    relevantTests: ['Control implementation review', 'Documentation assessment', 'Audit finding review']
  },
  {
    id: 'comp-009',
    question: 'Are there SOC 2 AI-specific controls?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'SOC 2 reports increasingly include AI-specific controls.',
    followUpQuestions: [
      'Is there a recent SOC 2 report?',
      'Are AI controls covered?',
      'What is the scope of the report?'
    ],
    relevantTests: ['SOC 2 control testing', 'Gap analysis', 'Control evidence review']
  },
  {
    id: 'comp-010',
    question: 'How is algorithmic impact assessment conducted?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Impact assessments identify potential harms and mitigation strategies.',
    followUpQuestions: [
      'Is there a formal AIA process?',
      'Who conducts the assessment?',
      'How often are assessments updated?'
    ],
    relevantTests: ['Assessment process review', 'Harm identification validation', 'Mitigation effectiveness']
  },

  // ============================================
  // NEW QUESTIONS - Model Architecture Extended
  // ============================================
  {
    id: 'model-007',
    question: 'What is the model parameter count and quantization level?',
    category: 'model',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Model size and quantization affect both capabilities and attack surface.',
    followUpQuestions: [
      'Is the model FP16, INT8, or INT4 quantized?',
      'What is the total parameter count?',
      'Are there different model sizes for different use cases?'
    ],
    relevantTests: ['Model fingerprinting', 'Quantization-specific attacks', 'Resource consumption testing']
  },
  {
    id: 'model-008',
    question: 'What inference framework is used for model serving?',
    category: 'model',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Different inference frameworks (vLLM, TensorRT-LLM, Triton, Ollama) have unique security characteristics.',
    followUpQuestions: [
      'What version of the serving framework is deployed?',
      'Are there known CVEs for this version?',
      'Is the serving layer hardened?'
    ],
    relevantTests: ['Framework vulnerability scanning', 'Configuration review', 'Version-specific exploit testing']
  },
  {
    id: 'model-009',
    question: 'What fine-tuning method was used?',
    category: 'model',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Fine-tuning method (Full, LoRA, QLoRA, Prefix tuning) affects model behavior and security.',
    followUpQuestions: [
      'Was RLHF or RLAIF applied?',
      'What safety fine-tuning was performed?',
      'What is the update frequency for model weights?'
    ],
    relevantTests: ['Fine-tuning data sensitivity review', 'Safety training effectiveness', 'Alignment testing']
  },
  {
    id: 'model-010',
    question: 'What multi-modal input capabilities does the model support?',
    category: 'model',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Multi-modal inputs (images, audio, video, documents) expand the attack surface significantly.',
    followUpQuestions: [
      'Is image/vision processing enabled?',
      'Is audio/speech processing enabled?',
      'What document types can be processed (PDF, Office, code)?'
    ],
    relevantTests: ['Multi-modal injection testing', 'Cross-modal attack testing', 'File upload security']
  },
  {
    id: 'model-011',
    question: 'Is the model API-based or self-hosted?',
    category: 'model',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'API-based vs self-hosted deployment has different security implications and control levels.',
    followUpQuestions: [
      'Which provider API is used (OpenAI, Anthropic, Azure, Bedrock)?',
      'If self-hosted, what GPU infrastructure is used?',
      'Is there multi-region deployment?'
    ],
    relevantTests: ['API security testing', 'Infrastructure assessment', 'Data residency verification']
  },
  {
    id: 'model-012',
    question: 'What model versioning and rollback capabilities exist?',
    category: 'model',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Rollback capabilities are essential for incident response when model issues are discovered.',
    followUpQuestions: [
      'How quickly can you rollback to a previous model version?',
      'Are previous model versions retained and for how long?',
      'Is there version-specific logging?'
    ],
    relevantTests: ['Rollback procedure review', 'Version integrity verification', 'Incident response testing']
  },

  // ============================================
  // NEW QUESTIONS - Data Pipeline & RAG Extended
  // ============================================
  {
    id: 'data-006',
    question: 'What RAG architecture type is implemented?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Different RAG architectures (Naive, Advanced, Modular, Graph RAG) have different security implications.',
    followUpQuestions: [
      'Is this standard semantic search or Graph RAG?',
      'Is there query routing or fusion?',
      'Are there multiple retrieval stages?'
    ],
    relevantTests: ['RAG architecture assessment', 'Retrieval manipulation testing', 'Context injection attacks']
  },
  {
    id: 'data-007',
    question: 'What chunking strategy and parameters are used?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Chunking strategy affects both retrieval quality and vulnerability to poisoning attacks.',
    followUpQuestions: [
      'What chunk size and overlap is used?',
      'Is chunking semantic, sentence-based, or recursive?',
      'How is metadata preserved in chunks?'
    ],
    relevantTests: ['Chunk boundary manipulation', 'Metadata injection', 'Context window exploitation']
  },
  {
    id: 'data-008',
    question: 'What embedding model is used for vectorization?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Embedding models can leak information and have their own vulnerabilities.',
    followUpQuestions: [
      'Is it OpenAI ada-002, Cohere, or sentence-transformers?',
      'Is the embedding model local or API-based?',
      'Can embeddings be inverted to recover text?'
    ],
    relevantTests: ['Embedding inversion attacks', 'Cross-embedding pollution', 'Model extraction via embeddings']
  },
  {
    id: 'data-009',
    question: 'What vector database is used and how is it secured?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Vector databases (Pinecone, Weaviate, Chroma, Milvus) hold sensitive document embeddings.',
    followUpQuestions: [
      'Is the vector DB hosted or self-managed?',
      'What access controls are implemented (API keys, IAM, RBAC)?',
      'Is encryption at rest and in transit enabled?'
    ],
    relevantTests: ['Vector DB access control testing', 'Encryption verification', 'Multi-tenancy isolation testing']
  },
  {
    id: 'data-010',
    question: 'How is document freshness and provenance tracked?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Stale or unverified documents can lead to outdated responses or poisoning attacks.',
    followUpQuestions: [
      'How often is the retrieval corpus updated?',
      'Is there document version control?',
      'How is document source verified?'
    ],
    relevantTests: ['Document freshness verification', 'Provenance manipulation', 'Stale content exploitation']
  },
  {
    id: 'data-011',
    question: 'What retrieval strategy is used (semantic, keyword, hybrid)?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Retrieval strategy affects susceptibility to different types of manipulation.',
    followUpQuestions: [
      'How many documents (Top-K) are retrieved?',
      'Is reranking applied?',
      'How is context window managed for long documents?'
    ],
    relevantTests: ['Retrieval manipulation', 'Ranking poisoning', 'Context overflow testing']
  },
  {
    id: 'data-012',
    question: 'What data sensitivity classification system is used?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Proper classification ensures appropriate security controls for different data types.',
    followUpQuestions: [
      'What classifications exist (public, internal, confidential, restricted)?',
      'How is classification enforced at retrieval time?',
      'Are there row-level or document-level security controls?'
    ],
    relevantTests: ['Classification bypass testing', 'Cross-classification access', 'Label manipulation']
  },
  {
    id: 'data-013',
    question: 'How is training data poisoning prevented?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Training data poisoning can cause persistent model misbehavior.',
    followUpQuestions: [
      'What data validation is performed before training?',
      'Are there anomaly detection mechanisms?',
      'How is fine-tuning data vetted?'
    ],
    relevantTests: ['Data poisoning simulation', 'Validation bypass testing', 'Backdoor trigger detection']
  },
  {
    id: 'data-014',
    question: 'What data versioning and lineage tracking exists?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Data lineage helps identify the source of model issues and enables rollback.',
    followUpQuestions: [
      'Is training data versioned?',
      'Can you trace model behavior to specific training data?',
      'What is the data retention policy?'
    ],
    relevantTests: ['Lineage verification', 'Version integrity testing', 'Data provenance audit']
  },
  {
    id: 'data-015',
    question: 'How is multi-tenancy data isolation implemented?',
    category: 'data',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Multi-tenant environments must prevent data leakage between tenants.',
    followUpQuestions: [
      'Is there namespace or collection-level isolation?',
      'How are tenant-specific embeddings separated?',
      'Are there shared resources that could leak data?'
    ],
    relevantTests: ['Cross-tenant data leakage', 'Namespace escape testing', 'Shared resource exploitation']
  },

  // ============================================
  // NEW QUESTIONS - Plugin & Tool Use Extended
  // ============================================
  {
    id: 'int-006',
    question: 'What code execution capabilities does the model have?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Code execution features create significant attack surface for prompt injection exploitation.',
    followUpQuestions: [
      'What languages are supported for execution?',
      'What sandboxing is implemented (containers, VMs, gVisor, Firecracker)?',
      'What resource limits are enforced (CPU, memory, time, disk)?'
    ],
    relevantTests: ['Sandbox escape testing', 'Resource exhaustion', 'Code injection attacks']
  },
  {
    id: 'int-007',
    question: 'What network isolation exists for code execution environments?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Network access from execution environments can enable data exfiltration and SSRF.',
    followUpQuestions: [
      'Can executed code make outbound network requests?',
      'Is there egress filtering?',
      'What internal services are accessible?'
    ],
    relevantTests: ['Network isolation testing', 'SSRF attempts', 'Data exfiltration channels']
  },
  {
    id: 'int-008',
    question: 'What database query capabilities does the model have?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Database access through AI can lead to SQL injection and data exfiltration.',
    followUpQuestions: [
      'What query types are allowed (SELECT only, full CRUD)?',
      'Is parameterized query enforcement in place?',
      'Are there query result size limits?'
    ],
    relevantTests: ['SQL injection testing', 'Query manipulation', 'Data extraction attempts']
  },
  {
    id: 'int-009',
    question: 'How are file read/write permissions scoped?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'File system access can enable path traversal and sensitive data access.',
    followUpQuestions: [
      'What directories are readable/writable?',
      'Is directory traversal prevention implemented?',
      'What file types are restricted?'
    ],
    relevantTests: ['Path traversal testing', 'File type bypass', 'Permission boundary testing']
  },
  {
    id: 'int-010',
    question: 'What web browsing capabilities are enabled?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Web browsing enables indirect prompt injection through external content.',
    followUpQuestions: [
      'Is there URL filtering or allowlisting?',
      'What content is extracted from pages?',
      'How is malicious content detected?'
    ],
    relevantTests: ['Indirect injection via web content', 'URL bypass testing', 'Content extraction manipulation']
  },
  {
    id: 'int-011',
    question: 'How are external API credentials managed for tool calls?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Tool calls to external APIs require secure credential handling.',
    followUpQuestions: [
      'Where are API credentials stored?',
      'Is there credential rotation?',
      'Are credentials exposed in logs or responses?'
    ],
    relevantTests: ['Credential exposure testing', 'API key extraction', 'Secret leakage in responses']
  },
  {
    id: 'int-012',
    question: 'What plugin vetting and approval process exists?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Untrusted plugins can introduce vulnerabilities and malicious functionality.',
    followUpQuestions: [
      'How are plugins reviewed before deployment?',
      'Can users install custom plugins?',
      'What permissions do plugins have?'
    ],
    relevantTests: ['Malicious plugin testing', 'Plugin permission bypass', 'Supply chain review']
  },
  {
    id: 'int-013',
    question: 'What timeout and rate limiting exists for tool calls?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Unbounded tool calls can lead to resource exhaustion and denial of service.',
    followUpQuestions: [
      'What is the timeout for individual tool calls?',
      'Is there rate limiting per user or globally?',
      'How are long-running operations handled?'
    ],
    relevantTests: ['Timeout bypass testing', 'Rate limit exhaustion', 'Resource consumption attacks']
  },
  {
    id: 'int-014',
    question: 'How are tool call results validated and sanitized?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Unvalidated tool responses can inject malicious content into model context.',
    followUpQuestions: [
      'Is tool output sanitized before processing?',
      'Are there size limits on tool responses?',
      'How are errors from tools handled?'
    ],
    relevantTests: ['Tool output injection', 'Response manipulation', 'Error handling exploitation']
  },
  {
    id: 'int-015',
    question: 'What malware scanning is performed on file uploads?',
    category: 'integration',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'File uploads can contain malware or malicious payloads.',
    followUpQuestions: [
      'What scanning engines are used?',
      'What file size limits exist?',
      'How are quarantined files handled?'
    ],
    relevantTests: ['Malware bypass testing', 'File type evasion', 'Size limit bypass']
  },

  // ============================================
  // NEW QUESTIONS - Autonomous Agents Extended
  // ============================================
  {
    id: 'agent-011',
    question: 'How is memory integrity verified to prevent poisoning?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Agent memory can be poisoned to persistently influence future behavior.',
    followUpQuestions: [
      'Are there checksums or signatures on stored memories?',
      'Can external content enter agent memory?',
      'How is memory content validated?'
    ],
    relevantTests: ['Memory poisoning attacks', 'Persistence bypass', 'Memory integrity testing']
  },
  {
    id: 'agent-012',
    question: 'What prevents unauthorized agent-to-agent communication?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Multi-agent systems can have communication channels exploited for attacks.',
    followUpQuestions: [
      'Is inter-agent communication authenticated?',
      'Can external parties inject messages between agents?',
      'What protocol is used (A2A, custom)?'
    ],
    relevantTests: ['Message injection', 'Agent impersonation', 'Communication channel hijacking']
  },
  {
    id: 'agent-013',
    question: 'What maximum iteration limits exist for agent actions?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Unbounded agent loops can lead to resource exhaustion and runaway behavior.',
    followUpQuestions: [
      'What is the maximum number of actions per goal?',
      'How is agent chain depth limited?',
      'What happens when limits are reached?'
    ],
    relevantTests: ['Loop exploitation', 'Chain depth bypass', 'Resource exhaustion via loops']
  },
  {
    id: 'agent-014',
    question: 'How is goal drift detected and prevented?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Goal drift can cause agents to pursue unintended objectives.',
    followUpQuestions: [
      'Are goals hardcoded or dynamic?',
      'Can user input influence goals?',
      'How are goal priorities enforced?'
    ],
    relevantTests: ['Goal hijacking attempts', 'Priority manipulation', 'Objective injection']
  },
  {
    id: 'agent-015',
    question: 'What approval timeout handling exists?',
    category: 'agent',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Approval timeouts need careful handling to prevent exploitation.',
    followUpQuestions: [
      'What happens when human approval times out?',
      'Can timeouts be manipulated?',
      'Are there default actions on timeout?'
    ],
    relevantTests: ['Timeout exploitation', 'Default action abuse', 'Approval bypass']
  },

  // ============================================
  // NEW QUESTIONS - Infrastructure Extended
  // ============================================
  {
    id: 'infra-006',
    question: 'How are model weights encrypted and access controlled?',
    category: 'infrastructure',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Model weights are valuable intellectual property requiring protection.',
    followUpQuestions: [
      'Are model files encrypted at rest?',
      'Who has access to model weight files?',
      'Is there model integrity verification (checksums, signatures)?'
    ],
    relevantTests: ['Weight file access testing', 'Encryption verification', 'Integrity check bypass']
  },
  {
    id: 'infra-007',
    question: 'What secrets management solution is used?',
    category: 'infrastructure',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'Proper secrets management prevents credential exposure.',
    followUpQuestions: [
      'Is HashiCorp Vault, AWS Secrets Manager, or Azure Key Vault used?',
      'What is the API key rotation policy?',
      'Is secret scanning enabled in code repos?'
    ],
    relevantTests: ['Secret exposure testing', 'Rotation policy verification', 'Secret sprawl audit']
  },
  {
    id: 'infra-008',
    question: 'What GPU resource isolation exists?',
    category: 'infrastructure',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Shared GPU resources can leak data between workloads.',
    followUpQuestions: [
      'Are GPU clusters shared across teams or users?',
      'How is GPU memory cleared between jobs?',
      'Are there custom CUDA kernels with security implications?'
    ],
    relevantTests: ['GPU memory analysis', 'Side-channel attack assessment', 'Resource isolation testing']
  },

  // ============================================
  // NEW QUESTIONS - Safety Extended
  // ============================================
  {
    id: 'safety-009',
    question: 'What factuality and grounding verification is implemented?',
    category: 'safety',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Grounding verification helps prevent hallucinations and misinformation.',
    followUpQuestions: [
      'Is there citation or source verification?',
      'How are hallucinations detected and flagged?',
      'Is there RAG-based fact checking?'
    ],
    relevantTests: ['Hallucination elicitation', 'Citation manipulation', 'Grounding bypass']
  },
  {
    id: 'safety-010',
    question: 'What language detection and filtering is applied?',
    category: 'safety',
    phase: 'pre-engagement',
    importance: 'medium',
    description: 'Language detection can prevent bypass attempts using non-English text.',
    followUpQuestions: [
      'What languages are supported vs blocked?',
      'How are mixed-language inputs handled?',
      'Are there character encoding filters?'
    ],
    relevantTests: ['Language-based bypass testing', 'Encoding manipulation', 'Mixed-language injection']
  },
  {
    id: 'safety-011',
    question: 'Is output watermarking implemented?',
    category: 'safety',
    phase: 'pre-engagement',
    importance: 'medium',
    description: 'Watermarking helps detect AI-generated content and trace origins.',
    followUpQuestions: [
      'What watermarking technique is used?',
      'Is watermarking detectable by external tools?',
      'Can watermarks be removed or forged?'
    ],
    relevantTests: ['Watermark detection testing', 'Watermark removal attempts', 'Forensic verification']
  },
  {
    id: 'safety-012',
    question: 'How are demographic and protected categories tested for bias?',
    category: 'safety',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Bias testing identifies discriminatory or unfair outputs.',
    followUpQuestions: [
      'What demographic categories are tested?',
      'What fairness metrics are monitored?',
      'Is there automated bias detection?'
    ],
    relevantTests: ['Bias elicitation testing', 'Demographic parity analysis', 'Fairness assessment']
  },

  // ============================================
  // NEW QUESTIONS - Testing Scope (NEW SECTION)
  // ============================================
  {
    id: 'scope-001',
    question: 'Is prompt injection testing authorized?',
    category: 'governance',
    phase: 'assessment',
    importance: 'critical',
    description: 'Explicit authorization is needed for prompt injection testing.',
    followUpQuestions: [
      'Are direct and indirect injection tests both authorized?',
      'What prompt patterns are in scope?',
      'Are automated injection tools authorized?'
    ],
    relevantTests: ['Direct prompt injection', 'Indirect prompt injection', 'Multi-turn injection']
  },
  {
    id: 'scope-002',
    question: 'Is jailbreaking testing authorized?',
    category: 'governance',
    phase: 'assessment',
    importance: 'critical',
    description: 'Jailbreak testing attempts to bypass safety guardrails.',
    followUpQuestions: [
      'What jailbreak techniques are authorized (role-play, encoding, multi-turn)?',
      'Are known jailbreak payloads authorized?',
      'Should successful jailbreaks be documented but not exploited?'
    ],
    relevantTests: ['DAN-style jailbreaks', 'Role-play bypasses', 'Encoding-based bypasses']
  },
  {
    id: 'scope-003',
    question: 'Is system prompt extraction testing authorized?',
    category: 'governance',
    phase: 'assessment',
    importance: 'critical',
    description: 'System prompt extraction reveals confidential business logic.',
    followUpQuestions: [
      'Should extracted prompts be included in reports?',
      'Are automated extraction tools authorized?',
      'What is the sensitivity classification of system prompts?'
    ],
    relevantTests: ['Direct extraction attacks', 'Completion-based extraction', 'Instruction hierarchy bypass']
  },
  {
    id: 'scope-004',
    question: 'Is training data extraction testing authorized?',
    category: 'governance',
    phase: 'assessment',
    importance: 'critical',
    description: 'Training data extraction tests for memorization vulnerabilities.',
    followUpQuestions: [
      'Are membership inference attacks authorized?',
      'Should extracted PII be documented?',
      'What is the sensitivity level of training data?'
    ],
    relevantTests: ['Prefix-based extraction', 'Membership inference', 'PII extraction attempts']
  },
  {
    id: 'scope-005',
    question: 'Is model extraction/inversion testing authorized?',
    category: 'governance',
    phase: 'assessment',
    importance: 'high',
    description: 'Model extraction attempts to steal model weights or architecture.',
    followUpQuestions: [
      'Are query-based extraction attacks authorized?',
      'Is distillation attack testing in scope?',
      'What is acceptable query volume for extraction attempts?'
    ],
    relevantTests: ['Query-based extraction', 'Distillation attacks', 'Side-channel extraction']
  },
  {
    id: 'scope-006',
    question: 'Is denial of service testing authorized?',
    category: 'governance',
    phase: 'assessment',
    importance: 'high',
    description: 'DoS testing can impact availability for other users.',
    followUpQuestions: [
      'What query rate is acceptable for testing?',
      'Are resource exhaustion attacks authorized?',
      'Should testing occur during off-peak hours?'
    ],
    relevantTests: ['Rate limit exhaustion', 'Context overflow', 'Token consumption attacks']
  },
  {
    id: 'scope-007',
    question: 'What test accounts and access levels will be provided?',
    category: 'governance',
    phase: 'assessment',
    importance: 'critical',
    description: 'Test accounts should mirror realistic user access patterns.',
    followUpQuestions: [
      'Are there multiple tier test accounts?',
      'Is there an admin test account?',
      'Are test accounts monitored separately?'
    ],
    relevantTests: ['Multi-tier testing', 'Privilege escalation', 'Cross-tenant testing']
  },
  {
    id: 'scope-008',
    question: 'What are the testing time windows and blackout periods?',
    category: 'governance',
    phase: 'assessment',
    importance: 'critical',
    description: 'Testing coordination prevents unintended production impact.',
    followUpQuestions: [
      'What timezone is used for testing hours?',
      'Are there maintenance windows to avoid?',
      'Who should be notified before testing?'
    ],
    relevantTests: ['All testing activities'],
    notes: 'Critical for rules of engagement'
  },

  // ============================================
  // NEW QUESTIONS - Compliance Extended
  // ============================================
  {
    id: 'comp-011',
    question: 'What EU AI Act transparency obligations apply?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'AI systems have disclosure requirements about their nature and capabilities.',
    followUpQuestions: [
      'Is AI nature disclosed to users?',
      'Are limitations documented?',
      'Is there a model card or AI fact sheet?'
    ],
    relevantTests: ['Disclosure compliance', 'Documentation accuracy', 'User notification testing']
  },
  {
    id: 'comp-012',
    question: 'What human oversight requirements are mandated?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'critical',
    description: 'High-risk AI systems require human oversight mechanisms.',
    followUpQuestions: [
      'Are there human-in-the-loop checkpoints?',
      'What decisions require human approval?',
      'Is there an emergency stop mechanism?'
    ],
    relevantTests: ['Human oversight bypass testing', 'Override capability review', 'Emergency stop effectiveness']
  },
  {
    id: 'comp-013',
    question: 'What sector-specific AI regulations apply?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Healthcare, finance, and other sectors have specific AI requirements.',
    followUpQuestions: [
      'Does FDA medical device guidance apply?',
      'Are there SEC/FINRA AI trading requirements?',
      'Do employment AI laws apply (NYC Local Law 144)?'
    ],
    relevantTests: ['Sector compliance audit', 'Documentation review', 'Control verification']
  },
  {
    id: 'comp-014',
    question: 'What cross-border data transfer mechanisms are used?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'GDPR and other regulations restrict international data transfers.',
    followUpQuestions: [
      'Are Standard Contractual Clauses in place?',
      'Is there adequacy decision coverage?',
      'What data localization requirements exist?'
    ],
    relevantTests: ['Data residency verification', 'Transfer mechanism audit', 'Localization testing']
  },
  {
    id: 'comp-015',
    question: 'Is there internal AI governance policy?',
    category: 'compliance',
    phase: 'pre-engagement',
    importance: 'high',
    description: 'Internal governance provides framework for responsible AI use.',
    followUpQuestions: [
      'Is there an AI ethics committee?',
      'What review process exists for new AI deployments?',
      'Are there acceptable use policies?'
    ],
    relevantTests: ['Policy compliance testing', 'Governance process review', 'Exception handling']
  }
]

// Helper functions
export const getQuestionsByCategory = (category: QuestionCategory): ScopingQuestion[] => {
  return scopingQuestions.filter(q => q.category === category)
}

export const getQuestionsByPhase = (phase: QuestionPhase): ScopingQuestion[] => {
  return scopingQuestions.filter(q => q.phase === phase)
}

export const getQuestionsByImportance = (importance: 'critical' | 'high' | 'medium' | 'low'): ScopingQuestion[] => {
  return scopingQuestions.filter(q => q.importance === importance)
}

export const getCriticalQuestions = (): ScopingQuestion[] => {
  return scopingQuestions.filter(q => q.importance === 'critical')
}

// Stats
export const questionStats = {
  totalQuestions: scopingQuestions.length,
  byCategory: questionCategories.reduce((acc, cat) => {
    acc[cat.id] = getQuestionsByCategory(cat.id).length
    return acc
  }, {} as Record<QuestionCategory, number>),
  byPhase: {
    'pre-engagement': getQuestionsByPhase('pre-engagement').length,
    reconnaissance: getQuestionsByPhase('reconnaissance').length,
    assessment: getQuestionsByPhase('assessment').length,
    'post-assessment': getQuestionsByPhase('post-assessment').length,
  },
  byImportance: {
    critical: getQuestionsByImportance('critical').length,
    high: getQuestionsByImportance('high').length,
    medium: getQuestionsByImportance('medium').length,
    low: getQuestionsByImportance('low').length,
  }
}
